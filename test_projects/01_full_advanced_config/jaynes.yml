version: 0
launch_log: /home/ubuntu/jaynes-launch.log
error_log: /home/ubuntu/jaynes-launch.err.log
cloud:
  ec2: &ec2 # missing profile/credential selection
    region: us-west-2
    image_id: ami-bd4fd7c5
    key_name: ge-berkeley
    security_group: torch-gym-prebuilt
    instance_type: c5.xlarge
    spot_price: 0.6
    iam_instance_profile_arn: arn:aws:iam::055406702465:instance-profile/main

mounts: # mount configurations
  - !mounts.S3Code &code_mount
    s3_prefix: s3://ge-bair/jaynes-debug
    local_path: .
    host_path: /global/geyang/
    container_path: /Users/geyang/learning-to-learn
    pypath: true
    excludes: "--exclude='*__pycache__' --exclude='*.git' --exclude='*.idea' --exclude='*.egg-info' --exclude='*.pkl'"
    compress: true
hosts:
  berkekley: &savio
    ip: localhost
    port: 42000
    username: ge.yang
    pem: ~/.ssh/id_rsa
  fair: &dev_fair
    ip: localhost
    port: 41000
    username: geyang
    pem: ~/.ssh/id_rsa
  obyern: &oberyn
    ip: oberyn.banatao.berkeley.edu
    username: ubuntu
    pem: ~/.ssh/incrementium-berkeley
  hodor: &hodor
    ip: hodor.banatao.berkeley.edu
    username: ubuntu
    pem: ~/.ssh/incrementium-berkeley
runners:
  - !runners.Docker &ssh_docker
    name: "some-job"  # only for docker
    image: "episodeyang/super-expert"
    startup: yes | pip install jaynes ml-logger -q
    envs: "LANG=utf-8"
    launch_directory: "{mounts[0].container_path}"
    ipc: host
    use_gpu: false
  - !runners.Slurm &fair_slurm
    startup: >-
      source /etc/profile;
      source ~/.profile;
      module load anaconda3/5.0.1;
      source activate playground
    envs: "LC_CTYPE=en_US.UTF-8 LANG=en_US.UTF-8 LANGUAGE=en_US SSH_TTY=/dev/pts/1 TERM=xterm-256color"
    partition: "dev,priority,uninterrupted"
    time_limit: "0:0:20"
    n_cpu: 40
    n_gpu: 0
    launch_directory: "{mounts[0].container_path}"
  - !runners.Slurm &lnl_slurm
    startup: >-
      source /etc/profile;
      source ~/.profile;
      module load anaconda3/5.0.1;
      source activate playground
    envs: "LC_CTYPE=en_US.UTF-8 LANG=en_US.UTF-8 LANGUAGE=en_US SSH_TTY=/dev/pts/1 TERM=xterm-256color"
    partition: "" # not clear what the partition is like
    time_limit: "0:0:20"
    n_cpu: 40
    n_gpu: 0
    launch_directory: "{mounts[0].container_path}"

modes: # todo: add support to modes.
  oberyn:
    runner: *ssh_docker
    launch:
      type: ssh
      <<: *oberyn
  hodor:
    runner: *ssh_docker
    launch:
      type: ssh
      <<: *hodor
  ec2:
    runner: *ssh_docker
    host:
      terminate_after: true
    launch:
      type: ec2
      <<: *ec2
  fair:
    runner: *fair_slurm
    launch:
      type: ssh
      <<: *dev_fair
  savio:
    runner: *lnl_slurm
    launch:
      type: ssh
      <<: *savio
run:  # this is specific to each launch, and is dynamically overwritten in-memory
  mounts:
    - *code_mount
verbose: true
